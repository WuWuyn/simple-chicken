# -*- coding: utf-8 -*-
"""
build_lsh_index.py

Má»¥c tiÃªu: Script nÃ y sáº½ thá»±c hiá»‡n cÃ¡c cÃ´ng viá»‡c sau:
1.  Äá»c tá»‡p `m-schema_final.txt` Ä‘á»ƒ xÃ¡c Ä‘á»‹nh cÃ¡c cá»™t cÃ³ kiá»ƒu dá»¯ liá»‡u lÃ  vÄƒn báº£n.
2.  Káº¿t ná»‘i Ä‘áº¿n cÆ¡ sá»Ÿ dá»¯ liá»‡u MS SQL Server.
3.  Truy váº¥n táº¥t cáº£ cÃ¡c giÃ¡ trá»‹ duy nháº¥t tá»« cÃ¡c cá»™t vÄƒn báº£n Ä‘Ã£ xÃ¡c Ä‘á»‹nh.
4.  XÃ¢y dá»±ng má»™t chá»‰ má»¥c LSH tá»« cÃ¡c giÃ¡ trá»‹ nÃ y báº±ng `datasketch`.
5.  LÆ°u chá»‰ má»¥c Ä‘Ã£ xÃ¢y dá»±ng ra má»™t tá»‡p `pickle` Ä‘á»ƒ tÃ¡i sá»­ dá»¥ng.
"""

import pyodbc
import pickle
from datasketch import MinHash, MinHashLSH
import re
import os

# --- CONFIGURATION ---
current_dir = os.path.dirname(os.path.abspath(__file__))
method_dir = os.path.join(current_dir, "..", "..")
SCHEMA_FILE_PATH = os.path.normpath(os.path.join(method_dir, "Offline", "build_lsh_index", "m-schema_final.txt"))
LSH_INDEX_PATH = os.path.normpath(os.path.join(method_dir, "Offline", "build_lsh_index", "full_db_lsh.pkl"))
NUM_PERM = 128  # Number of hash functions for MinHash
THRESHOLD = 0.3  # Jaccard similarity threshold (lowered from 0.8 for better recall)

# âš ï¸ QUAN TRá»ŒNG: Äiá»n thÃ´ng tin káº¿t ná»‘i Ä‘áº¿n database cá»§a báº¡n vÃ o Ä‘Ã¢y
DB_CONNECTION_STRING = (
    "DRIVER={ODBC Driver 17 for SQL Server};"
    "SERVER=localhost;"  # Vd: 'localhost' hoáº·c '192.168.1.10'
    "DATABASE=text_to_sql_final;"     # TÃªn database
    "UID=sa;"              # TÃªn ngÆ°á»i dÃ¹ng
    "PWD=123456;"              # Máº­t kháº©u
)

# --- HÃ m PhÃ¢n tÃ­ch Schema Ä‘á»ƒ xÃ¡c Ä‘á»‹nh Cá»™t VÄƒn báº£n ---
# HÃ m nÃ y Ä‘á»c tá»‡p schema vÃ  tráº£ vá» má»™t danh sÃ¡ch cÃ¡c cáº·p `(tÃªn_báº£ng, tÃªn_cá»™t)` 
# cho nhá»¯ng cá»™t cÃ³ kiá»ƒu dá»¯ liá»‡u lÃ  vÄƒn báº£n (`VARCHAR`, `NVARCHAR`).

def parse_schema_for_text_columns(file_path):
    """
    Parses the schema file to get a list of (table, column) for text-based columns.
    """
    print(f"Äang phÃ¢n tÃ­ch schema Ä‘á»ƒ xÃ¡c Ä‘á»‹nh cÃ¡c cá»™t vÄƒn báº£n: {file_path}")
    if not os.path.exists(file_path):
        print(f"Lá»–I: KhÃ´ng tÃ¬m tháº¥y tá»‡p {file_path}")
        return []
        
    text_columns = []
    current_table = None
    text_types = ['varchar', 'nvarchar'] # CÃ¡c kiá»ƒu dá»¯ liá»‡u Ä‘Æ°á»£c coi lÃ  vÄƒn báº£n
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line.startswith('# Table:'):
                current_table = line.replace('# Table:', '').strip()
            elif current_table and line.startswith('('):
                match = re.search(r'\((?P<name>\w+):(?P<type>[\w\(\)]+)', line)
                if match:
                    col_name = match.group('name')
                    col_type = match.group('type').lower()
                    if any(ttype in col_type for ttype in text_types):
                        text_columns.append((current_table, col_name))
    print(f"ÄÃ£ tÃ¬m tháº¥y {len(text_columns)} cá»™t vÄƒn báº£n Ä‘á»ƒ láº­p chá»‰ má»¥c.")
    return text_columns

# --- Logic ChÃ­nh: Káº¿t ná»‘i, Truy váº¥n vÃ  XÃ¢y dá»±ng Chá»‰ má»¥c LSH ---
# Pháº§n nÃ y sáº½ thá»±c hiá»‡n toÃ n bá»™ quÃ¡ trÃ¬nh:
# 1.  Khá»Ÿi táº¡o Ä‘á»‘i tÆ°á»£ng `MinHashLSH`.
# 2.  Láº¥y danh sÃ¡ch cÃ¡c cá»™t vÄƒn báº£n.
# 3.  Má»Ÿ káº¿t ná»‘i Ä‘áº¿n DB.
# 4.  Láº·p qua tá»«ng cá»™t, truy váº¥n dá»¯ liá»‡u vÃ  thÃªm vÃ o chá»‰ má»¥c LSH.
# 5.  ÄÃ³ng káº¿t ná»‘i vÃ  lÆ°u chá»‰ má»¥c ra file.

def create_enhanced_minhash(value: str, num_perm: int = 128) -> MinHash:
    """
    Táº¡o MinHash Ä‘Æ°á»£c cáº£i thiá»‡n cho strings ngáº¯n báº±ng cÃ¡ch sá»­ dá»¥ng:
    1. Character-level shingles (n-grams)
    2. Prefix/suffix patterns
    3. Edit distance approximation
    """
    m = MinHash(num_perm=num_perm)
    value_lower = value.lower().strip()
    
    # 1. Add original value
    m.update(value_lower.encode('utf8'))
    
    # 2. Add character-level bigrams and trigrams
    for n in [2, 3]:
        if len(value_lower) >= n:
            for i in range(len(value_lower) - n + 1):
                ngram = value_lower[i:i+n]
                m.update(ngram.encode('utf8'))
    
    # 3. Add prefix/suffix patterns cho cÃ¡c ID codes
    if len(value_lower) >= 2:
        # Prefix patterns (SE, AI, etc.)
        prefix = value_lower[:2]
        m.update(f"PREFIX_{prefix}".encode('utf8'))
        
        # Suffix patterns (01, 02, FA23, etc.)
        if len(value_lower) >= 3:
            suffix = value_lower[-2:]
            m.update(f"SUFFIX_{suffix}".encode('utf8'))
    
    # 4. Add character type patterns
    pattern = ""
    for char in value_lower:
        if char.isalpha():
            pattern += "L"  # Letter
        elif char.isdigit():
            pattern += "D"  # Digit
        else:
            pattern += "S"  # Symbol
    m.update(f"PATTERN_{pattern}".encode('utf8'))
    
    return m

def main():
    """
    HÃ m chÃ­nh thá»±c thi toÃ n bá»™ logic.
    """
    # 1. Khá»Ÿi táº¡o LSH
    # âœ… Sá»­a lá»—i: Giáº£m threshold xuá»‘ng Ä‘á»ƒ cÃ³ recall tá»‘t hÆ¡n
    lsh = MinHashLSH(threshold=THRESHOLD, num_perm=NUM_PERM)

    # 2. Láº¥y danh sÃ¡ch cÃ¡c cá»™t vÄƒn báº£n
    text_columns = parse_schema_for_text_columns(SCHEMA_FILE_PATH)
    
    if not text_columns:
        print("KhÃ´ng cÃ³ cá»™t vÄƒn báº£n nÃ o Ä‘Æ°á»£c tÃ¬m tháº¥y. Káº¿t thÃºc chÆ°Æ¡ng trÃ¬nh.")
        return

    conn = None
    indexed_value_count = 0
    try:
        # 3. Káº¿t ná»‘i Database
        print("Äang káº¿t ná»‘i Ä‘áº¿n cÆ¡ sá»Ÿ dá»¯ liá»‡u...")
        conn = pyodbc.connect(DB_CONNECTION_STRING)
        cursor = conn.cursor()
        print("Káº¿t ná»‘i cÆ¡ sá»Ÿ dá»¯ liá»‡u thÃ nh cÃ´ng.")

        # 4. Láº·p qua tá»«ng cá»™t, truy váº¥n vÃ  láº­p chá»‰ má»¥c
        for i, (table_name, column_name) in enumerate(text_columns):
            print(f"  ({i+1}/{len(text_columns)}) Äang láº­p chá»‰ má»¥c cho {table_name}.{column_name}...")
            
            sql_query = f"SELECT DISTINCT [{column_name}] FROM [{table_name}] WHERE [{column_name}] IS NOT NULL AND LTRIM(RTRIM([{column_name}])) != ''"
            
            try:
                cursor.execute(sql_query)
                rows = cursor.fetchall()
                
                for row in rows:
                    original_value = row[0]
                    if original_value and isinstance(original_value, str) and original_value.strip():
                        cleaned_value = original_value.strip().lower()
                        
                        key = f"{table_name}:{column_name}:{original_value}"
                        
                        m = create_enhanced_minhash(cleaned_value)
                        
                        lsh.insert(key, m)
                        indexed_value_count += 1
            except pyodbc.Error as ex:
                sqlstate = ex.args[0]
                print(f"    ! Lá»–I khi thá»±c thi truy váº¥n cho {table_name}.{column_name}: {sqlstate}")

    except pyodbc.Error as ex:
        print(f"Lá»–I NGHIÃŠM TRá»ŒNG: Káº¿t ná»‘i DB tháº¥t báº¡i. Vui lÃ²ng kiá»ƒm tra láº¡i DB_CONNECTION_STRING.")
        print(ex)
    finally:
        if conn:
            conn.close()
            print("\nÄÃ£ Ä‘Ã³ng káº¿t ná»‘i cÆ¡ sá»Ÿ dá»¯ liá»‡u.")

    # 5. LÆ°u chá»‰ má»¥c LSH ra file
    if indexed_value_count > 0:
        with open(LSH_INDEX_PATH, 'wb') as f:
            pickle.dump(lsh, f)
        
        print("\n--- XÃ¢y dá»±ng Chá»‰ má»¥c LSH HOÃ€N Táº¤T! ---")
        print(f"Threshold sá»­ dá»¥ng: {THRESHOLD}")
        print(f"Tá»•ng sá»‘ giÃ¡ trá»‹ duy nháº¥t Ä‘Ã£ Ä‘Æ°á»£c láº­p chá»‰ má»¥c: {indexed_value_count}")
        print(f"Chá»‰ má»¥c LSH Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {os.path.abspath(LSH_INDEX_PATH)}")
        
        # ğŸ§ª TEST: Kiá»ƒm tra sá»‘ lÆ°á»£ng keys trong LSH
        if hasattr(lsh, 'keys'):
            try:
                total_keys_in_lsh = len(lsh.keys) if lsh.keys else 0
                print(f"âœ… XÃ¡c nháº­n: LSH index chá»©a {total_keys_in_lsh} keys")
            except:
                print(f"âœ… XÃ¡c nháº­n: LSH index Ä‘Ã£ Ä‘Æ°á»£c táº¡o (khÃ´ng thá»ƒ Ä‘áº¿m keys)")
        
        # ğŸ§ª TEST: Query thá»­ vá»›i má»™t giÃ¡ trá»‹ Ä‘á»ƒ xem threshold áº£nh hÆ°á»Ÿng nhÆ° tháº¿ nÃ o
        test_keywords = ["AI_K1_FA23", "ai_k1_fa23", "SE", "Student", "Course", "SE04"]
        for keyword in test_keywords:
            test_hash = create_enhanced_minhash(keyword)
            test_results = lsh.query(test_hash)
            print(f"ğŸ” Test query vá»›i '{keyword}' (threshold={THRESHOLD}): {len(test_results)} results")
            if test_results:
                print(f"  VÃ­ dá»¥ káº¿t quáº£: {test_results[:3]}")
    else:
        print("\nKhÃ´ng cÃ³ giÃ¡ trá»‹ nÃ o Ä‘Æ°á»£c láº­p chá»‰ má»¥c. Tá»‡p LSH khÃ´ng Ä‘Æ°á»£c táº¡o.")

if __name__ == '__main__':
    main()