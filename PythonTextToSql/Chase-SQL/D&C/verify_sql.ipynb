{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec5fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "import google.api_core.exceptions\n",
    "import google.generativeai.types as safety_types\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5756be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DANH SÁCH API KEYS CHO GEMINI\n",
    "# Thay thế bằng các API key thực tế của bạn\n",
    "GEMINI_API_KEYS = [\n",
    "    os.environ.get('GOOGLE_API_KEY')\n",
    "]\n",
    "\n",
    "# Giới hạn tỷ lệ cho mỗi API key\n",
    "API_RATE_LIMIT_PER_MINUTE = 100\n",
    "API_KEY_COOLDOWN_SECONDS = 70 # 1 phút\n",
    "\n",
    "# Cấu trúc để theo dõi việc sử dụng API key\n",
    "api_key_usage = {key: {\"count\": 0, \"last_reset_time\": time.time()} for key in GEMINI_API_KEYS}\n",
    "current_api_key_index = 0 # Bắt đầu với API key đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4dd450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_available_api_key():\n",
    "    global current_api_key_index\n",
    "    global api_key_usage\n",
    "    start_index = current_api_key_index\n",
    "    while True:\n",
    "        api_key = GEMINI_API_KEYS[current_api_key_index]\n",
    "        usage_stats = api_key_usage[api_key]\n",
    "        current_time = time.time()\n",
    "        if current_time - usage_stats[\"last_reset_time\"] > API_KEY_COOLDOWN_SECONDS:\n",
    "            usage_stats[\"count\"] = 0\n",
    "            usage_stats[\"last_reset_time\"] = current_time\n",
    "        if usage_stats[\"count\"] < API_RATE_LIMIT_PER_MINUTE:\n",
    "            usage_stats[\"count\"] += 1\n",
    "            genai.configure(api_key=api_key)\n",
    "            return api_key\n",
    "        current_api_key_index = (current_api_key_index + 1) % len(GEMINI_API_KEYS)\n",
    "        if current_api_key_index == start_index:\n",
    "            current_time = time.time()\n",
    "            wait_times = []\n",
    "            for key_str_loop, usage_stats_loop in api_key_usage.items():\n",
    "                time_since_last_reset = current_time - usage_stats_loop[\"last_reset_time\"]\n",
    "                if time_since_last_reset > API_KEY_COOLDOWN_SECONDS:\n",
    "                    wait_times.append(0)\n",
    "                else:\n",
    "                    wait_times.append(API_KEY_COOLDOWN_SECONDS - time_since_last_reset + 1)\n",
    "            min_wait_time = min(wt for wt in wait_times if wt > 0) if any(wt > 0 for wt in wait_times) else 0.5\n",
    "            \n",
    "            if min_wait_time > 0:\n",
    "                 print(f\"All API keys are on cooldown. Waiting for {min_wait_time:.2f} seconds...\")\n",
    "                 time.sleep(min_wait_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e293e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV files\n",
    "source_df = pd.read_csv('question.csv')\n",
    "target_df = pd.read_csv('result_QP.csv') # Giữ nguyên tên file target của bạn\n",
    "\n",
    "# Ensure both DataFrames have the same number of rows\n",
    "assert len(source_df) == len(target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5c4978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_column_mapping():\n",
    "    results_validation = []\n",
    "    model_name_to_use = 'gemini-2.0-flash' \n",
    "    print(f\"Using LLM model: {model_name_to_use}\")\n",
    "\n",
    "    # CẬP NHẬT VALID_LLM_OUTPUTS\n",
    "    VALID_LLM_OUTPUTS = {\n",
    "        \"Wrong data selection - Missing column\",\n",
    "        # \"Wrong data selection - Missing row\", # Đã xóa\n",
    "        # \"Wrong data selection - Extra row\",   # Đã xóa\n",
    "        \"Wrong data selection - Different content\",\n",
    "        \"Extra column\",\n",
    "        \"True\"\n",
    "    }\n",
    "    MAX_RETRIES_PER_RECORD = len(GEMINI_API_KEYS) + 1 if GEMINI_API_KEYS else 1\n",
    "\n",
    "    for i in range(len(source_df)):\n",
    "        expected_result_str = source_df.loc[i, 'Result']\n",
    "        actual_result_str = target_df.loc[i, 'Result']\n",
    "        \n",
    "        print(f\"\\n--- Record {i} ---\")\n",
    "\n",
    "        # PROMPT ĐÃ ĐƯỢC CẬP NHẬT\n",
    "        prompt = f\"\"\"\n",
    "You are an SQL result verifier. Your task is to compare an 'expected_result' (source) with an 'actual_result' (target) and determine the validation status.\n",
    "The results are provided as JSON strings representing lists of objects.\n",
    "**Crucial Assumption:** Assume all objects within a single JSON result list (either expected or actual) have the same set of keys. If a list is empty (e.g., `[]`), it has no keys and no rows. If a list contains empty objects (e.g., `[ {{}} ]`), it has rows, but each object has an empty set of keys.\n",
    "\n",
    "Expected Result (Source):\n",
    "```json\n",
    "{expected_result_str}\n",
    "```\n",
    "\n",
    "Actual Result (Target):\n",
    "```json\n",
    "{actual_result_str}\n",
    "```\n",
    "\n",
    "Based on the following rules, determine the validation status. Respond with *only one* of these exact strings:\n",
    "- 'Wrong data selection - Missing column'\n",
    "- 'Wrong data selection - Different content'\n",
    "- 'Extra column'\n",
    "- 'True'\n",
    "\n",
    "**Definitions:**\n",
    "Let `expected_data` be the list of objects parsed from Expected Result.\n",
    "Let `actual_data` be the list of objects parsed from Actual Result.\n",
    "\n",
    "To determine `expected_keys` (as a set):\n",
    "- If `expected_data` is an empty list (e.g., `[]`), then `expected_keys` is an empty set.\n",
    "- Else (if `expected_data` is not empty, e.g., `[ {{}}]` or `[{{\"a\":1}}]`), then `expected_keys` is the set of keys from the first object `expected_data[0]`. (If `expected_data[0]` is `{{}}`, `expected_keys` is an empty set).\n",
    "Determine `actual_keys` (as a set) using the same logic with `actual_data`.\n",
    "\n",
    "**RULES (evaluate strictly in the order presented. Once a rule's conditions are met, select its corresponding validation status and do not proceed to subsequent rules.):**\n",
    "\n",
    "1.  **'Wrong data selection - Missing column':**\n",
    "    Apply if `expected_keys` is not empty AND (`actual_keys` is empty OR `expected_keys` IS NOT a subset of `actual_keys`).\n",
    "    *This means actual_result is missing one or more columns that are present in expected_result.*\n",
    "    *Example:* Expected `[{{\"a\":1, \"b\":2}}]`, Actual `[{{\"a\":1}}]` -> 'Wrong data selection - Missing column' (missing 'b').\n",
    "    *Example:* Expected `[{{\"a\":1}}]`, Actual `[{{}}]` -> 'Wrong data selection - Missing column' (missing 'a').\n",
    "    *Example:* Expected `[{{\"a\":1}}]`, Actual `[]` -> 'Wrong data selection - Missing column' (expected column 'a', actual has no columns due to no rows).\n",
    "\n",
    "2.  **'Extra column':**\n",
    "    Apply if Rule 1 does NOT apply, AND\n",
    "    (`expected_keys` IS a subset of `actual_keys` OR `expected_keys` is empty) AND `actual_keys` IS a proper superset of `expected_keys` (i.e., `actual_keys` contains all keys from `expected_keys` AND `actual_keys` has additional keys not in `expected_keys`).\n",
    "    *This means actual_result has all expected columns plus one or more extra columns.*\n",
    "    *Example:* Expected `[{{\"a\":1}}]`, Actual `[{{\"a\":1, \"b\":2}}]` -> 'Extra column'.\n",
    "    *Example:* Expected `[]`, Actual `[{{\"a\":1}}]` -> 'Extra column'.\n",
    "    *Example:* Expected `[{{}}]`, Actual `[{{\"a\":1}}]` -> 'Extra column'.\n",
    "\n",
    "    *If execution reaches this point, it implies: `expected_keys` and `actual_keys` are identical sets (could both be empty). The only remaining differences can be in the number of rows or the content of the data objects, or if they are perfectly True.*\n",
    "\n",
    "3.  **'Wrong data selection - Different content':**\n",
    "    Apply if Rules 1 and 2 do NOT apply, AND (`len(actual_data) != len(expected_data)` OR `expected_data` IS NOT identical to `actual_data`).\n",
    "    To check for non-identical data when row counts are the same: Compare `expected_data[i]` with `actual_data[i]` for each row `i`. For each object pair, compare all key-value pairs (since keys are now known to be identical). If any value differs for any key in any row, or if the order of rows is different such that `expected_data[i]` does not match `actual_data[i]`, the content is different.\n",
    "    *This means column structure is compatible (Rule 1 and 2 did not apply), but either the number of rows is different, or the number of rows is the same but the data values within the rows differ (or row order is effectively different).*\n",
    "    *Example (different row count - missing):* Expected `[{{\"a\":1}}, {{\"a\":2}}]`, Actual `[{{\"a\":1}}]` -> 'Wrong data selection - Different content'.\n",
    "    *Example (different row count - extra):* Expected `[{{\"a\":1}}]`, Actual `[{{\"a\":1}}, {{\"a\":2}}]` -> 'Wrong data selection - Different content'.\n",
    "    *Example (different row count - expected empty, actual has rows):* Expected `[]`, Actual `[{{}}]` -> 'Wrong data selection - Different content'.\n",
    "    *Example (same row count, different values):* Expected `[{{\"a\":1, \"b\":2}}]`, Actual `[{{\"a\":1, \"b\":3}}]` -> 'Wrong data selection - Different content'.\n",
    "    *Example (same row count, different row order):* Expected `[{{\"a\":1}}, {{\"a\":2}}]`, Actual `[{{\"a\":2}}, {{\"a\":1}}]` -> 'Wrong data selection - Different content'.\n",
    "\n",
    "4.  **'True':**\n",
    "    Apply if Rules 1, 2, and 3 do NOT apply.\n",
    "    *This means `expected_keys` and `actual_keys` are identical, `len(actual_data)` and `len(expected_data)` are identical, AND `expected_data` IS identical to `actual_data` (all corresponding objects and their key-value pairs match in the same order).*\n",
    "    *Example:* Expected `[{{\"a\":1, \"b\":2}}]`, Actual `[{{\"a\":1, \"b\":2}}]` -> 'True'.\n",
    "    *Example:* Expected `[]`, Actual `[]` -> 'True'.\n",
    "    *Example:* Expected `[{{}}]`, Actual `[{{}}]` -> 'True'.\n",
    "\n",
    "Validation Status:\n",
    "\"\"\"\n",
    "        \n",
    "        llm_verdict = \"API Error\" \n",
    "        current_attempt = 0\n",
    "        prompt_processed_successfully = False\n",
    "\n",
    "        while current_attempt < MAX_RETRIES_PER_RECORD and not prompt_processed_successfully:\n",
    "            current_call_api_key_info = \"N/A\"\n",
    "            selected_api_key = None\n",
    "            current_attempt += 1\n",
    "            \n",
    "            try:\n",
    "                selected_api_key = get_next_available_api_key()\n",
    "                if not selected_api_key:\n",
    "                    print(f\"    Attempt {current_attempt}/{MAX_RETRIES_PER_RECORD}: No API key available even after waiting. Marking record {i} as API Error.\")\n",
    "                    llm_verdict = \"API Error (No Key)\" \n",
    "                    break \n",
    "\n",
    "                current_call_api_key_info = f\"...{selected_api_key[-4:]}\"\n",
    "                print(f\"    Attempt {current_attempt}/{MAX_RETRIES_PER_RECORD} for record {i} (Key: {current_call_api_key_info})\")\n",
    "                \n",
    "                model = genai.GenerativeModel(model_name=model_name_to_use)\n",
    "                \n",
    "                current_safety_settings = [\n",
    "                    {\n",
    "                        \"category\": safety_types.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "                        \"threshold\": safety_types.HarmBlockThreshold.BLOCK_NONE,\n",
    "                    },\n",
    "                    {\n",
    "                        \"category\": safety_types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "                        \"threshold\": safety_types.HarmBlockThreshold.BLOCK_NONE,\n",
    "                    },\n",
    "                    {\n",
    "                        \"category\": safety_types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "                        \"threshold\": safety_types.HarmBlockThreshold.BLOCK_NONE,\n",
    "                    },\n",
    "                    {\n",
    "                        \"category\": safety_types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "                        \"threshold\": safety_types.HarmBlockThreshold.BLOCK_NONE,\n",
    "                    },\n",
    "                ]\n",
    "                \n",
    "                response = model.generate_content(\n",
    "                    contents=prompt, \n",
    "                    safety_settings=current_safety_settings\n",
    "                )\n",
    "                \n",
    "                if hasattr(response, 'text') and response.text:\n",
    "                    raw_verdict = response.text.strip()\n",
    "                    if raw_verdict in VALID_LLM_OUTPUTS:\n",
    "                        llm_verdict = raw_verdict\n",
    "                        prompt_processed_successfully = True \n",
    "                    else:\n",
    "                        print(f\"    LLM returned an unexpected response: '{raw_verdict}'. Treating as an error for this attempt.\")\n",
    "                        llm_verdict = \"LLM Format Error\" \n",
    "                else:\n",
    "                    if hasattr(response, 'prompt_feedback') and response.prompt_feedback and hasattr(response.prompt_feedback, 'block_reason') and response.prompt_feedback.block_reason:\n",
    "                        print(f\"    LLM call blocked for record {i} (Key: {current_call_api_key_info}). Reason: {response.prompt_feedback.block_reason}. Treating as an error for this attempt.\")\n",
    "                    else:\n",
    "                        candidate_text = \"\"\n",
    "                        try:\n",
    "                            if response.candidates and response.candidates[0].content and response.candidates[0].content.parts:\n",
    "                               candidate_text = response.candidates[0].content.parts[0].text if response.candidates[0].content.parts[0].text else \"\"\n",
    "                        except (IndexError, AttributeError):\n",
    "                            pass \n",
    "                            \n",
    "                        if candidate_text:\n",
    "                            raw_verdict = candidate_text.strip()\n",
    "                            if raw_verdict in VALID_LLM_OUTPUTS:\n",
    "                                llm_verdict = raw_verdict\n",
    "                                prompt_processed_successfully = True\n",
    "                            else:\n",
    "                                print(f\"    LLM returned unexpected text in candidate parts: '{raw_verdict}'. Treating as error.\")\n",
    "                                llm_verdict = \"LLM Format Error (Candidate)\"\n",
    "                        else:\n",
    "                            print(f\"    LLM returned no text and no block reason for record {i} (Key: {current_call_api_key_info}). Treating as an error for this attempt.\")\n",
    "                    if not prompt_processed_successfully:\n",
    "                         llm_verdict = \"LLM No Response\" \n",
    "\n",
    "                if prompt_processed_successfully:\n",
    "                    break \n",
    "\n",
    "            except Exception as e:\n",
    "                is_retryable_error = False\n",
    "                error_message = str(e).lower()\n",
    "\n",
    "                if isinstance(e, google.api_core.exceptions.ResourceExhausted) or \"429\" in error_message:\n",
    "                    is_retryable_error = True\n",
    "                    print(f\"      Error (429 Resource Exhausted) on attempt {current_attempt} for record {i} with key {current_call_api_key_info}. Details: {e}\")\n",
    "                elif isinstance(e, google.api_core.exceptions.ServiceUnavailable) or \"503\" in error_message:\n",
    "                    is_retryable_error = True\n",
    "                    print(f\"      Error (Service Unavailable/503) on attempt {current_attempt} for record {i} with key {current_call_api_key_info}. Details: {e}\")\n",
    "                elif isinstance(e, google.api_core.exceptions.DeadlineExceeded):\n",
    "                    is_retryable_error = True\n",
    "                    print(f\"      Error (DeadlineExceeded) on attempt {current_attempt} for record {i} with key {current_call_api_key_info}. Details: {e}\")\n",
    "                elif isinstance(e, google.api_core.exceptions.InternalServerError) or \"500\" in error_message :\n",
    "                    is_retryable_error = True\n",
    "                    print(f\"      Error (InternalServerError/500) on attempt {current_attempt} for record {i} with key {current_call_api_key_info}. Details: {e}\")\n",
    "                else:\n",
    "                    print(f\"      Non-retryable error on attempt {current_attempt} for record {i} with key {current_call_api_key_info}: {type(e).__name__} - {e}\")\n",
    "                \n",
    "                llm_verdict = \"API Error\" \n",
    "\n",
    "                if is_retryable_error and current_attempt < MAX_RETRIES_PER_RECORD:\n",
    "                    print(f\"      Retrying prompt for record {i}...\")\n",
    "                else: \n",
    "                    if not is_retryable_error:\n",
    "                        print(f\"      Not retrying for record {i} due to non-retryable error.\")\n",
    "                    else:\n",
    "                        print(f\"      Max retries ({MAX_RETRIES_PER_RECORD}) reached for record {i}.\")\n",
    "                    break \n",
    "        \n",
    "        if not prompt_processed_successfully and llm_verdict not in VALID_LLM_OUTPUTS :\n",
    "            print(f\"    Failed to get a valid LLM response for record {i} after {current_attempt} attempts. Final verdict: {llm_verdict}\")\n",
    "        \n",
    "        results_validation.append(llm_verdict)\n",
    "        print(f\"  LLM Validation for Record {i}: {llm_verdict}\")\n",
    "        \n",
    "    return results_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed640e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = check_column_mapping()\n",
    "target_df['Validation'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05305df",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df.to_csv('valid_QP_updated_rules.csv', index=False) # Đổi tên file output để không ghi đè\n",
    "print(\"Đã ghi kết quả vào file 'valid_QP_updated_rules.csv' với cột 'Validation'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d908fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
